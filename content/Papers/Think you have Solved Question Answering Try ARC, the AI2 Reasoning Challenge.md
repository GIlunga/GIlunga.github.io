---
created: 2023-07-24
updated: 2023-07-24
---
>[!info]  
> **Year**:: 2018
> **Title**: Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge
> **Authors**: Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick, Oyvind Tafjord
>   
> **URL**: http://arxiv.org/abs/1803.05457
> **Status**:: Want to Read
> **Stars**::
> **Tags**:


> [!Abstract]  
> We present a new question set, text corpus, and baselines assembled to encourage AI research in advanced question answering. Together, these constitute the AI2 Reasoning Challenge (ARC), which requires far more powerful knowledge and reasoning than previous challenges such as SQuAD or SNLI. The ARC question set is partitioned into a Challenge Set and an Easy Set, where the Challenge Set contains only questions answered incorrectly by both a retrieval-based algorithm and a word co-occurence algorithm. The dataset contains only natural, grade-school science questions (authored for human tests), and is the largest public-domain set of this kind (7,787 questions). We test several baselines on the Challenge Set, including leading neural models from the SQuAD and SNLI tasks, and ﬁnd that none are able to significantly outperform a random baseline, reﬂecting the difﬁcult nature of this task. We are also releasing the ARC Corpus, a corpus of 14M science sentences relevant to the task, and implementations of the three neural baseline models tested. Can your model perform better? We pose ARC as a challenge to the community.  

> [!Quick Summary]  
>**Summary**::



%% Import Date: 2023-07-25T23:06:12.416+01:00 %%
